## PredictingRaitings
Описание файлов:
1. В папке data все исходные и промежуточные данные в формате csv. (+исходные данные в pgn).
  Промежуточными являются файлы, которые записаны после окончания работы с одним из исполняемых файлов.
  +тестовые наборы данных, которые я искала сама.
2. extracting.py - считываются все исходные csv и записываются в более удобном виде (так как считывание исходнных файлов > 2 часов).
3. exploring.ipynb - первичный анализ данных, удаление выбросов, поиск простых взаимосвязей.
4. features.ipynb - извлечение признаков из оценок и внутренних показателей партий. Снова используется пакет chess, но уже не считываем исходный pgn, а формируем свои игры по заданным ходам в формате UCI (предположительно так быстрее, чем снова читать исходники и отбирать нужные партии).
5. features_processing.ipynb - простая попытка оработки признаков.
6. main.py - прототип приложения для тестирования.
7. В папке models различные модели и таблички с результатами. Самым важным файлом является baseline.ipynb, на его основе строятся другие.

#### Некоторые важные замечания:
1. Данных, которые мы реально можем использовать - первые 25000 (для проверки результата). Тестовые данные без рейтинга проверить никак не можем. (или сравнивать результаты с решением 1-го места?).
2. Значения в MAE не стоит воспринимать однозначно, так как такая оценка является неустойчивой.
3. Пока непонятно, как взаимодействовать с движком (выдает странные результаты).
4. Спрогнозированные рейтинги сосредоточены вокруг среднего (~2250). Поэтому плохо прогнозируются <2000 и > 2500. Надо разделять по группам.

#### Что улучшить:
1. Взять больше партий (например, https://github.com/rozim/ChessData)
2. Пересчитать оценки на большей глубине + получить список лучших ходов.
3. Возможно имеет смысл рассматривать ходы как последовательности и анализировать таким образом (однако, это сложнее и не согласуется со статьями Kenneth Regan - у него ходы независимы друг от друга).
4. Задать разные модели не только по цветам и результатам, но так же и сгруппировать их по исходному рейтингу для обучения (есть информация, что модели показывают плохой результат на гроссмейстерах 2500+).
P.S. А я, оказывается, об этом уже думала, но надеялась видимо, что модель покажет лучший результат.
