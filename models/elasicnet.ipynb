{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import ElasticNet,.ElasticNetCV\n",
    "from sklearn import model_selection as ms\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "\n",
    "from warnings import simplefilter\n",
    "\n",
    "rand_st=4\n",
    "simplefilter(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elos=pd.read_csv(r'C:\\Users\\Asus\\PredictingRatings\\data\\clean_elos.csv')\n",
    "elos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.read_csv(r'C:\\Users\\Asus\\PredictingRatings\\data\\features.csv')\n",
    "print(features.info())\n",
    "print(features.shape)\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_white=elos['WhiteElo']\n",
    "target_black=elos['BlackElo']\n",
    "target_mean=elos['MeanElos']\n",
    "target_diff=elos['DiffElos']\n",
    "target_sum=elos['SumElos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1=features[:500]\n",
    "target_sum1=target_sum[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test =ms.train_test_split(features1, target_sum1, test_size = 0.3,random_state=rand_st)\n",
    "print ('Train data size: {} instances \\nTest data size: {} instances'.format(len(X_train), len(Y_train)))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_report(pred_target,predictions):\n",
    "    mae_report=mae(target_sum,sum_pred)\n",
    "    print ('MAE = {:.3f}'.format(mae_report))\n",
    "    \n",
    "    rmse_report = (mse(target_sum, sum_pred))**0.5\n",
    "    print ('RMSE = {:.3f}'.format(rmse_report))\n",
    "    \n",
    "    corr_coef = pearsonr(target_sum1,sum_pred)\n",
    "    print(\"Correlation coefficient = {:.3f}\".format(corr_coef[0]))\n",
    "    \n",
    "    return (mae_report,rmse_report,corr_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridTune(params,classifiers,folds):\n",
    "    mae = make_scorer(metrics.mean_absolute_error)\n",
    "   \n",
    "    grid = ms.GridSearchCV(classifiers,\n",
    "                           params,  # настройка параметров через кросс-валидацию\n",
    "                           refit=True,    # переобучение по лучшим найденным параметрам   \n",
    "                           scoring=mae,\n",
    "                           n_jobs=-1,\n",
    "                           cv=ms.StratifiedKFold(n_splits=folds))\n",
    "\n",
    "    \n",
    "    grid_best_model = grid.fit(X_train,Y_train)\n",
    "\n",
    "    print(\"Лучшие параметры для MAE:\")\n",
    "    print(grid_best_model.best_params_)\n",
    "    print('\\nЛучший алгоритм:')\n",
    "    print(grid_best_model.best_estimator_)\n",
    "    return grid_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params =[]\n",
    "\n",
    "start = time.time()\n",
    "lr=LinearRegression(random_state=rand_st,n_jobs=-1')\n",
    "lr_model=GridTune(lr_params,lr,2)\n",
    "lr_predictions=lr_model.predict(X_test)\n",
    "scores=predictions_report(Y_test,lr_predictions)\n",
    "full_time=round((time.time() - start)/2,3)\n",
    "print(full_time, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('MAE = {:.3f}'.format(scores[0]))\n",
    "print ('RMSE = {:.3f}'.format(scores[1]))\n",
    "print(\"Correlation coefficient = {:.3f}\".format(scores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.read_table(r'C:\\Users\\Asus\\PredictingRatings\\models\\results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.append(pd.Series([str(lr_1), mae1,rmse1, \n",
    "                                  corr_coef1[0],full_time1,'Обучение только на победах белых -> прогноз ретйтинга белых'],\n",
    "                                 index=output.columns ),\n",
    "                      ignore_index=True)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel(r'C:\\Users\\Asus\\PredictingRatings\\models\\results.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
